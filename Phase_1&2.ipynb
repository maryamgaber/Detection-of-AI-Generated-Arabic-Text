{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maryamgaber/Detection-of-AI-Generated-Arabic-Text/blob/main/Phase_1%262.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91e227c4",
      "metadata": {
        "id": "91e227c4"
      },
      "source": [
        "## Task 1.2: Use the datasets library from Hugging Face to download the arabic- generated-abstracts dataset directly into a Python environment (By Google Colab)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# 1️⃣ Set the folder where your notebooks are located\n",
        "# If your notebooks are in the current working directory, keep \".\"\n",
        "notebooks_folder = \".\"  # change to \"/content/your_folder\" if needed\n",
        "\n",
        "# 2️⃣ Walk through all files in the folder\n",
        "for root, dirs, files in os.walk(notebooks_folder):\n",
        "    for file in files:\n",
        "        if file.endswith(\".ipynb\"):\n",
        "            notebook_path = os.path.join(root, file)\n",
        "\n",
        "            # Load notebook JSON\n",
        "            with open(notebook_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                nb = json.load(f)\n",
        "\n",
        "            # Remove widgets metadata if exists\n",
        "            if \"widgets\" in nb.get(\"metadata\", {}):\n",
        "                del nb[\"metadata\"][\"widgets\"]\n",
        "                # Save cleaned notebook\n",
        "                with open(notebook_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                    json.dump(nb, f, indent=1)\n",
        "                print(f\"Cleaned widgets metadata in: {notebook_path}\")\n",
        "            else:\n",
        "                print(f\"No widgets metadata found in: {notebook_path}\")\n",
        "\n",
        "print(\"✅ All notebooks are cleaned and ready for GitHub upload!\")\n"
      ],
      "metadata": {
        "id": "A_L8O6l87tz5"
      },
      "id": "A_L8O6l87tz5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "792b9e4b",
      "metadata": {
        "id": "792b9e4b"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets\n",
        "# !pip install python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be1008dc",
      "metadata": {
        "id": "be1008dc"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from huggingface_hub import login\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "hf_token = os.getenv(\"HF_TOKEN\")\n",
        "login(token=hf_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dea3272",
      "metadata": {
        "id": "5dea3272"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Login using e.g. `huggingface-cli login` to access this dataset\n",
        "dataset = load_dataset(\"KFUPM-JRCAI/arabic-generated-abstracts\")\n",
        "print(dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "997695cc",
      "metadata": {
        "id": "997695cc"
      },
      "source": [
        "### Task 1.3: Perform initial data exploration:\n",
        "#### 1- Load and inspect the dataset structure (columns, data types).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1452b10e",
      "metadata": {
        "id": "1452b10e"
      },
      "outputs": [],
      "source": [
        "# Inspect column names and data types for one split (e.g., 'by_polishing')\n",
        "print(\"\\nFeatures in 'by_polishing':\")\n",
        "print(dataset['by_polishing'].features)\n",
        "\n",
        "# Check dataset info (shape, structure, statistics)\n",
        "print(\"\\nDataset info for 'by_polishing':\")\n",
        "print(dataset['by_polishing'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3afb712",
      "metadata": {
        "id": "c3afb712"
      },
      "source": [
        "#### 2- Check the distribution of the target variable (label: human vs. AI- generated) for dataset[\"by_polishing\"].\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "477d5b06",
      "metadata": {
        "id": "477d5b06"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a289922",
      "metadata": {
        "id": "5a289922"
      },
      "outputs": [],
      "source": [
        "# Choose one split (e.g., by_polishing)\n",
        "split1 = dataset[\"by_polishing\"]\n",
        "\n",
        "# Count human-written abstracts\n",
        "num_human = len(split1[\"original_abstract\"])\n",
        "\n",
        "# Count AI-generated abstracts (4 per row)\n",
        "num_ai = len(split1[\"allam_generated_abstract\"]) \\\n",
        "       + len(split1[\"jais_generated_abstract\"]) \\\n",
        "       + len(split1[\"llama_generated_abstract\"]) \\\n",
        "       + len(split1[\"openai_generated_abstract\"])\n",
        "\n",
        "print(\"Number of human abstracts:\", num_human)\n",
        "print(\"Number of AI-generated abstracts:\", num_ai)\n",
        "\n",
        "# Distribution ratio\n",
        "total = num_human + num_ai\n",
        "print(\"Human %:\", round(num_human / total * 100, 2))\n",
        "print(\"AI %:\", round(num_ai / total * 100, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "079c4cb2",
      "metadata": {
        "id": "079c4cb2"
      },
      "source": [
        "#### 3- Assess data quality: check for missing values, duplicates, and inconsistencies:\n",
        "\n",
        "\n",
        "Missing values → any None/NaN in columns\n",
        "\n",
        "Duplicates → same abstract appearing multiple times\n",
        "\n",
        "Inconsistencies → like empty strings \" \" or unusual data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbce6d3d",
      "metadata": {
        "id": "fbce6d3d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Convert to pandas for easier checks\n",
        "df = pd.DataFrame(split1)\n",
        "\n",
        "# 1. Missing values\n",
        "print(\"Missing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"_________________________________________\")\n",
        "\n",
        "# 2. Duplicates\n",
        "print(\"\\nNumber of duplicate rows:\", df.duplicated().sum())\n",
        "\n",
        "# Also check duplicates in each column separately\n",
        "for col in df.columns:\n",
        "    print(f\"Duplicates in column {col}: {df[col].duplicated().sum()}\")\n",
        "print(\"_________________________________________\")\n",
        "\n",
        "\n",
        "# 3. Inconsistencies: empty strings or only spaces\n",
        "for col in df.columns:\n",
        "    empty_count = df[col].apply(lambda x: str(x).strip() == \"\").sum()\n",
        "    print(f\"Empty/blank values in column {col}: {empty_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e825541a",
      "metadata": {
        "id": "e825541a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tEON2s3Ql-tP"
      },
      "id": "tEON2s3Ql-tP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Check the distribution of the target variable (label: human vs. AI- generated) for dataset[\"from_title\"]."
      ],
      "metadata": {
        "id": "Zm30k1ocmDPZ"
      },
      "id": "Zm30k1ocmDPZ"
    },
    {
      "cell_type": "code",
      "source": [
        "split2 = dataset[\"from_title\"]\n",
        "\n",
        "# Count human-written abstracts\n",
        "num_human = len(split2[\"original_abstract\"])\n",
        "\n",
        "# Count AI-generated abstracts (4 per row)\n",
        "num_ai = len(split2[\"allam_generated_abstract\"]) \\\n",
        "       + len(split2[\"jais_generated_abstract\"]) \\\n",
        "       + len(split2[\"llama_generated_abstract\"]) \\\n",
        "       + len(split2[\"openai_generated_abstract\"])\n",
        "\n",
        "print(\"Number of human abstracts:\", num_human)\n",
        "print(\"Number of AI-generated abstracts:\", num_ai)\n",
        "\n",
        "# Distribution ratio\n",
        "total = num_human + num_ai\n",
        "print(\"Human %:\", round(num_human / total * 100, 2))\n",
        "print(\"AI %:\", round(num_ai / total * 100, 2))"
      ],
      "metadata": {
        "id": "Qu6VuwEemLPI"
      },
      "id": "Qu6VuwEemLPI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Convert to pandas for easier checks\n",
        "df = pd.DataFrame(split2)\n",
        "\n",
        "# 1. Missing values\n",
        "print(\"Missing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"_________________________________________\")\n",
        "\n",
        "# 2. Duplicates\n",
        "print(\"\\nNumber of duplicate rows:\", df.duplicated().sum())\n",
        "\n",
        "# Also check duplicates in each column separately\n",
        "for col in df.columns:\n",
        "    print(f\"Duplicates in column {col}: {df[col].duplicated().sum()}\")\n",
        "print(\"_________________________________________\")\n",
        "\n",
        "\n",
        "# 3. Inconsistencies: empty strings or only spaces\n",
        "for col in df.columns:\n",
        "    empty_count = df[col].apply(lambda x: str(x).strip() == \"\").sum()\n",
        "    print(f\"Empty/blank values in column {col}: {empty_count}\")\n"
      ],
      "metadata": {
        "id": "w6jHiSM3mca2"
      },
      "id": "w6jHiSM3mca2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WJsUl6zjoKX9"
      },
      "id": "WJsUl6zjoKX9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Check the distribution of the target variable (label: human vs. AI- generated) for dataset[\"from_title_and_content\"]."
      ],
      "metadata": {
        "id": "C0x8QZttoM6E"
      },
      "id": "C0x8QZttoM6E"
    },
    {
      "cell_type": "code",
      "source": [
        "split3 = dataset[\"from_title_and_content\"]\n",
        "\n",
        "# Count human-written abstracts\n",
        "num_human = len(split3[\"original_abstract\"])\n",
        "\n",
        "# Count AI-generated abstracts (4 per row)\n",
        "num_ai = len(split3[\"allam_generated_abstract\"]) \\\n",
        "       + len(split3[\"jais_generated_abstract\"]) \\\n",
        "       + len(split3[\"llama_generated_abstract\"]) \\\n",
        "       + len(split3[\"openai_generated_abstract\"])\n",
        "\n",
        "print(\"Number of human abstracts:\", num_human)\n",
        "print(\"Number of AI-generated abstracts:\", num_ai)\n",
        "\n",
        "# Distribution ratio\n",
        "total = num_human + num_ai\n",
        "print(\"Human %:\", round(num_human / total * 100, 2))\n",
        "print(\"AI %:\", round(num_ai / total * 100, 2))"
      ],
      "metadata": {
        "id": "pABqYSyioUJ-"
      },
      "id": "pABqYSyioUJ-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Convert to pandas for easier checks\n",
        "df = pd.DataFrame(split3)\n",
        "\n",
        "# 1. Missing values\n",
        "print(\"Missing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"_________________________________________\")\n",
        "\n",
        "# 2. Duplicates\n",
        "print(\"\\nNumber of duplicate rows:\", df.duplicated().sum())\n",
        "\n",
        "# Also check duplicates in each column separately\n",
        "for col in df.columns:\n",
        "    print(f\"Duplicates in column {col}: {df[col].duplicated().sum()}\")\n",
        "print(\"_________________________________________\")\n",
        "\n",
        "\n",
        "# 3. Inconsistencies: empty strings or only spaces\n",
        "for col in df.columns:\n",
        "    empty_count = df[col].apply(lambda x: str(x).strip() == \"\").sum()\n",
        "    print(f\"Empty/blank values in column {col}: {empty_count}\")\n"
      ],
      "metadata": {
        "id": "h2Oc6JoroyAT"
      },
      "id": "h2Oc6JoroyAT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 2 -preprocessing"
      ],
      "metadata": {
        "id": "Jx_JLBu23w_x"
      },
      "id": "Jx_JLBu23w_x"
    },
    {
      "cell_type": "code",
      "source": [
        "# task 2.1: Arabic Text Preprocessing\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "from datasets import load_dataset\n"
      ],
      "metadata": {
        "id": "cINVvDvxo1sY"
      },
      "id": "cINVvDvxo1sY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required NLTK resources\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "dge6SB2mp1kx"
      },
      "id": "dge6SB2mp1kx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check columns\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "xTeRHx-rp43g"
      },
      "id": "xTeRHx-rp43g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Arabic text cleaning functions"
      ],
      "metadata": {
        "id": "fTPi6B6V5H6K"
      },
      "id": "fTPi6B6V5H6K"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove tashkeel (diacritics)\n",
        "def remove_diacritics(text):\n",
        "    arabic_diacritics = re.compile(r'[\\u0617-\\u061A\\u064B-\\u0652]')\n",
        "    return re.sub(arabic_diacritics, '', text)"
      ],
      "metadata": {
        "id": "xvK4KAkWqNt-"
      },
      "id": "xvK4KAkWqNt-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize Arabic text\n",
        "def normalize_arabic(text):\n",
        "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
        "    text = re.sub(\"ى\", \"ي\", text)\n",
        "    text = re.sub(\"ؤ\", \"و\", text)\n",
        "    text = re.sub(\"ئ\", \"ي\", text)\n",
        "    text = re.sub(\"ة\", \"ه\", text)\n",
        "    text = re.sub(\"[^؀-ۿ ]+\", \" \", text)  # remove non-Arabic chars\n",
        "    return text"
      ],
      "metadata": {
        "id": "v_IZB2y2q9Ip"
      },
      "id": "v_IZB2y2q9Ip",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize stopwords and stemmer\n",
        "arabic_stopwords = set(stopwords.words(\"arabic\"))\n",
        "stemmer = ISRIStemmer()"
      ],
      "metadata": {
        "id": "BuV9q2b0rCtW"
      },
      "id": "BuV9q2b0rCtW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Full preprocessing pipeline\n",
        "def preprocess_text(text):\n",
        "    text = str(text)\n",
        "    text = remove_diacritics(text)\n",
        "    text = normalize_arabic(text)\n",
        "    tokens = text.split()\n",
        "    tokens = [w for w in tokens if w not in arabic_stopwords]\n",
        "    tokens = [stemmer.stem(w) for w in tokens]\n",
        "    return \" \".join(tokens)"
      ],
      "metadata": {
        "id": "8qhJ9wWVrFZV"
      },
      "id": "8qhJ9wWVrFZV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing\n",
        "text_columns = [\n",
        "    'original_abstract',\n",
        "    'allam_generated_abstract',\n",
        "    'jais_generated_abstract',\n",
        "    'llama_generated_abstract',\n",
        "    'openai_generated_abstract'\n",
        "]\n",
        "for col in text_columns:\n",
        "    clean_col = col + \"_clean\"\n",
        "    df[clean_col] = df[col].apply(preprocess_text)\n",
        "print(\" Preprocessing complete! Here are the new columns:\")\n",
        "print(df.columns)\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "VDEQ2M1RrOW3"
      },
      "id": "VDEQ2M1RrOW3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Task 2.2: Exploratory Data Analysis (EDA)\n",
        "\n"
      ],
      "metadata": {
        "id": "pn9LXPqr8w0R"
      },
      "id": "pn9LXPqr8w0R"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "aoZRcVsRrQP_"
      },
      "id": "aoZRcVsRrQP_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine AI abstracts into one column\n",
        "ai_texts = pd.concat([\n",
        "    df['allam_generated_abstract_clean'],\n",
        "    df['jais_generated_abstract_clean'],\n",
        "    df['llama_generated_abstract_clean'],\n",
        "    df['openai_generated_abstract_clean']\n",
        "], axis=0).dropna().tolist()\n"
      ],
      "metadata": {
        "id": "HOYjhcprtNin"
      },
      "id": "HOYjhcprtNin",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human_texts = df['original_abstract_clean'].dropna().tolist()\n"
      ],
      "metadata": {
        "id": "FCqA9LqQtWRf"
      },
      "id": "FCqA9LqQtWRf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Statistical Analysis ---\n",
        "def text_stats(texts):\n",
        "    words = [w for txt in texts for w in txt.split()]  # Split into words\n",
        "    avg_word_len = np.mean([len(w) for w in words]) #متوسط طول الكلمة\n",
        "    avg_sent_len = np.mean([len(txt.split()) for txt in texts]) #متوسط طول الجملة\n",
        "    vocab = set(words)\n",
        "    ttr = len(vocab) / len(words) #حساب التنوع اللغوي الموجود في النص\n",
        "    return avg_word_len, avg_sent_len, ttr"
      ],
      "metadata": {
        "id": "Rxu2GEbjtYB0"
      },
      "id": "Rxu2GEbjtYB0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats_human = text_stats(human_texts)\n",
        "stats_ai = text_stats(ai_texts)"
      ],
      "metadata": {
        "id": "3d7QPSKPtegb"
      },
      "id": "3d7QPSKPtegb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Statistical Summary:\")\n",
        "print(f\"Human-written: Avg word len={stats_human[0]:.2f}, Avg sent len={stats_human[1]:.2f}, TTR={stats_human[2]:.3f}\")\n",
        "print(f\"AI-generated : Avg word len={stats_ai[0]:.2f}, Avg sent len={stats_ai[1]:.2f}, TTR={stats_ai[2]:.3f}\")"
      ],
      "metadata": {
        "id": "CZ8_8ik6thHC"
      },
      "id": "CZ8_8ik6thHC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- N-gram Frequency ---\n",
        "def plot_top_ngrams(texts, n=2, top_k=15):\n",
        "    from sklearn.feature_extraction.text import CountVectorizer\n",
        "    vec = CountVectorizer(ngram_range=(n, n))\n",
        "    bag = vec.fit_transform(texts)\n",
        "    sum_words = bag.sum(axis=0)\n",
        "    freqs = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    freqs = sorted(freqs, key=lambda x: x[1], reverse=True)[:top_k]\n",
        "    words, counts = zip(*freqs)\n",
        "    plt.figure(figsize=(10,4))\n",
        "    sns.barplot(x=list(counts), y=list(words))\n",
        "    plt.title(f\"Top {top_k} {n}-grams – {n}-grams for {'Human' if texts==human_texts else 'AI'} abstracts\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\n Top Bigrams for Human-written abstracts:\")\n",
        "plot_top_ngrams(human_texts, n=2)\n",
        "\n",
        "print(\"\\n Top Bigrams for AI-generated abstracts:\")\n",
        "plot_top_ngrams(ai_texts, n=2)\n"
      ],
      "metadata": {
        "id": "BkVMwa8ztljQ"
      },
      "id": "BkVMwa8ztljQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentence Length Distribution\n",
        "\n",
        "#Purpose: Compare how long the abstracts are (in words or characters).\n",
        "#AI-generated text might be longer, more repetitive, or more uniform than human-written text."
      ],
      "metadata": {
        "id": "LdxguIGMTYd5"
      },
      "id": "LdxguIGMTYd5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df[\"human_length\"] = df[\"original_abstract\"].apply(lambda x: len(x.split()))\n",
        "df[\"openai_length\"] = df[\"openai_generated_abstract\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.hist(df[\"human_length\"], bins=30, alpha=0.6, label=\"Human-written\", color='blue')\n",
        "plt.hist(df[\"openai_length\"], bins=30, alpha=0.6, label=\"Openai-generated\", color='orange')\n",
        "plt.xlabel(\"Sentence Length (words)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Sentence Length Distribution\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bVWvzW9R4R87"
      },
      "id": "bVWvzW9R4R87",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vocabulary Richness (Type–Token Ratio)\n",
        "\n",
        "#Purpose: See how diverse the vocabulary is — humans often use richer language."
      ],
      "metadata": {
        "id": "WiNWQ6UYTix6"
      },
      "id": "WiNWQ6UYTix6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def type_token_ratio(text):\n",
        "    words = text.split()\n",
        "    return len(set(words)) / len(words) if words else 0\n",
        "\n",
        "df[\"human_ttr\"] = df[\"original_abstract\"].apply(type_token_ratio)\n",
        "df[\"openai_ttr\"] = df[\"openai_generated_abstract\"].apply(type_token_ratio)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.boxplot([df[\"human_ttr\"], df[\"openai_ttr\"]], labels=[\"Human\", \"Open AI\"])\n",
        "plt.title(\"Vocabulary Richness (Type–Token Ratio)\")\n",
        "plt.ylabel(\"TTR Score\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V1ZkBmyy4VKS"
      },
      "id": "V1ZkBmyy4VKS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Word Frequency Comparison (Side-by-Side Bar Plot)\n",
        "\n",
        "#Purpose: See which words are overused by Open AI vs humans."
      ],
      "metadata": {
        "id": "ExguSdxZT7SM"
      },
      "id": "ExguSdxZT7SM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "human_words = \" \".join(df[\"original_abstract\"]).split()\n",
        "Openai_words = \" \".join(df[\"openai_generated_abstract\"]).split()\n",
        "\n",
        "human_freq = Counter(human_words)\n",
        "ai_freq = Counter(Openai_words)\n",
        "\n",
        "common_words = set(list(human_freq.keys())[:100]) & set(list(ai_freq.keys())[:100])\n",
        "\n",
        "data = []\n",
        "for w in common_words:\n",
        "    data.append((w, human_freq[w], ai_freq[w]))\n",
        "\n",
        "freq_df = pd.DataFrame(data, columns=[\"word\", \"human\", \"Open ai\"]).sort_values(\"human\", ascending=False)[:15]\n",
        "\n",
        "freq_df.plot(x=\"word\", kind=\"bar\", figsize=(10,5), title=\"Top Words: Human vs Open AI\", rot=45)\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r7kBVIbv4XGn"
      },
      "id": "r7kBVIbv4XGn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZX6XpBtP3hP9"
      },
      "id": "ZX6XpBtP3hP9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QklOCVNb4WQS"
      },
      "id": "QklOCVNb4WQS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HMZzWtam3FVa"
      },
      "id": "HMZzWtam3FVa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_DIN97bNtrXI"
      },
      "id": "_DIN97bNtrXI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tt0dqujDtrzk"
      },
      "id": "Tt0dqujDtrzk",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "master_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}